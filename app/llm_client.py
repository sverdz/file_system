"""LLM client for document analysis."""
from __future__ import annotations

import json
from typing import Dict, Optional, Tuple
import requests
from rich.console import Console

console = Console()


class LLMClient:
    """–ö–ª—ñ—î–Ω—Ç –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ LLM API (Claude —Ç–∞ ChatGPT)."""

    def __init__(
        self,
        provider: str,
        api_key: str,
        model: str,
        enabled: bool = False,
    ):
        self.provider = provider
        self.api_key = api_key
        self.model = model
        self.enabled = enabled
        self.request_count = 0
        self.total_tokens = 0

    def analyze_document(
        self, text: str, max_length: int = 2000
    ) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """
        –ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é LLM.

        Returns:
            (category, date, summary) –∞–±–æ (None, None, None) —è–∫—â–æ LLM –≤–∏–º–∫–Ω–µ–Ω–æ
        """
        if not self.enabled or not self.api_key:
            return None, None, None

        # –û–±—Ä—ñ–∑–∞—î–º–æ —Ç–µ–∫—Å—Ç –¥–æ —Ä–æ–∑—É–º–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É
        text_sample = text[:max_length] if len(text) > max_length else text

        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ü–µ–π –¥–æ–∫—É–º–µ–Ω—Ç —ñ –¥–∞–π –≤—ñ–¥–ø–æ–≤—ñ–¥—å —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON:

–¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞:
{text_sample}

–í—ñ–¥–ø–æ–≤—ñ–¥—å –º–∞—î –º—ñ—Å—Ç–∏—Ç–∏:
1. "category" - —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–¥–æ–≥–æ–≤—ñ—Ä, —Ä–∞—Ö—É–Ω–æ–∫, –∞–∫—Ç, –ø—Ä–æ—Ç–æ–∫–æ–ª, –ª–∏—Å—Ç, –Ω–∞–∫–∞–∑, –∑–≤—ñ—Ç, –∫–æ—à—Ç–æ—Ä–∏—Å, —Ç–µ–Ω–¥–µ—Ä, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü—ñ—è, –¥–æ–≤—ñ–¥–∫–∞, –¢–ó, —Å–ø–µ—Ü–∏—Ñ—ñ–∫–∞—Ü—ñ—è, –∞–±–æ —ñ–Ω—à–µ)
2. "date" - –¥–∞—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —É —Ñ–æ—Ä–º–∞—Ç—ñ YYYY-MM-DD (—è–∫—â–æ —î)
3. "summary" - –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞ (2-3 —Ä–µ—á–µ–Ω–Ω—è, –º–∞–∫—Å–∏–º—É–º 200 —Å–∏–º–≤–æ–ª—ñ–≤)

–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —Ç—ñ–ª—å–∫–∏ –≤–∞–ª—ñ–¥–Ω–∏–º JSON –±–µ–∑ –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç—É."""

        try:
            console.print(
                f"\n[dim]ü§ñ LLM –∑–∞–ø–∏—Ç ({self.provider}):[/dim]",
                style="dim",
            )
            console.print(f"[dim]   –¢–µ–∫—Å—Ç: {len(text_sample)} —Å–∏–º–≤–æ–ª—ñ–≤[/dim]")

            response_text = self._make_request(prompt)

            if response_text:
                console.print(f"[dim]‚úì LLM –≤—ñ–¥–ø–æ–≤—ñ–¥—å –æ—Ç—Ä–∏–º–∞–Ω–æ ({len(response_text)} —Å–∏–º–≤–æ–ª—ñ–≤)[/dim]")

                # –ü–∞—Ä—Å–∏–º–æ JSON
                try:
                    # –í–∏–¥–∞–ª—è—î–º–æ –º–æ–∂–ª–∏–≤—ñ markdown backticks
                    clean_response = response_text.strip()
                    if clean_response.startswith("```"):
                        clean_response = clean_response.split("```")[1]
                        if clean_response.startswith("json"):
                            clean_response = clean_response[4:]
                    clean_response = clean_response.strip()

                    data = json.loads(clean_response)
                    category = data.get("category")
                    date = data.get("date")
                    summary = data.get("summary")

                    console.print(
                        f"[dim]   –ö–∞—Ç–µ–≥–æ—Ä—ñ—è: {category}, –î–∞—Ç–∞: {date}[/dim]"
                    )
                    console.print(f"[dim]   –û–ø–∏—Å: {summary[:50]}...[/dim]")

                    return category, date, summary
                except json.JSONDecodeError as e:
                    console.print(
                        f"[yellow]‚ö† –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É JSON: {e}[/yellow]"
                    )
                    console.print(f"[dim]–í—ñ–¥–ø–æ–≤—ñ–¥—å: {response_text[:200]}[/dim]")
                    return None, None, None
            else:
                return None, None, None

        except Exception as e:
            console.print(f"[yellow]‚ö† –ü–æ–º–∏–ª–∫–∞ LLM –∑–∞–ø–∏—Ç—É: {e}[/yellow]")
            return None, None, None

    def _make_request(self, prompt: str) -> Optional[str]:
        """–í–∏–∫–æ–Ω–∞—Ç–∏ –∑–∞–ø–∏—Ç –¥–æ LLM API."""
        self.request_count += 1

        try:
            if self.provider == "claude":
                return self._request_claude(prompt)
            elif self.provider == "chatgpt":
                return self._request_openai(prompt)
            else:
                return None
        except Exception as e:
            console.print(f"[red]–ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Ç—É –¥–æ {self.provider}: {e}[/red]")
            return None

    def _request_claude(self, prompt: str) -> Optional[str]:
        """–ó–∞–ø–∏—Ç –¥–æ Claude API."""
        headers = {
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01",
            "content-type": "application/json",
        }

        data = {
            "model": self.model or "claude-3-haiku-20240307",
            "max_tokens": 500,
            "messages": [{"role": "user", "content": prompt}],
        }

        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers=headers,
            json=data,
            timeout=30,
        )

        if response.status_code == 200:
            result = response.json()
            # –û–Ω–æ–≤–ª—é—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            if "usage" in result:
                self.total_tokens += result["usage"].get("input_tokens", 0)
                self.total_tokens += result["usage"].get("output_tokens", 0)

            content = result.get("content", [])
            if content and len(content) > 0:
                return content[0].get("text", "")
        else:
            console.print(
                f"[red]Claude API –ø–æ–º–∏–ª–∫–∞ {response.status_code}: {response.text}[/red]"
            )

        return None

    def _request_openai(self, prompt: str) -> Optional[str]:
        """–ó–∞–ø–∏—Ç –¥–æ OpenAI API."""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        data = {
            "model": self.model or "gpt-3.5-turbo",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 500,
            "temperature": 0.3,
        }

        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=30,
        )

        if response.status_code == 200:
            result = response.json()
            # –û–Ω–æ–≤–ª—é—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            if "usage" in result:
                self.total_tokens += result["usage"].get("total_tokens", 0)

            choices = result.get("choices", [])
            if choices and len(choices) > 0:
                return choices[0].get("message", {}).get("content", "")
        else:
            console.print(
                f"[red]OpenAI API –ø–æ–º–∏–ª–∫–∞ {response.status_code}: {response.text}[/red]"
            )

        return None

    def get_stats(self) -> Dict[str, int]:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è."""
        return {
            "requests": self.request_count,
            "tokens": self.total_tokens,
        }


__all__ = ["LLMClient"]
