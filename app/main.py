"""Entry point for the modular File Inventory Tool."""
from __future__ import annotations

import json
import mimetypes
import sys
import time
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional

from app import deps

deps.ensure_ready()

from colorama import Fore, Style, init as colorama_init
from rich.console import Console
from rich.table import Table

from app.classify import classify_text, summarize_text
from app.config import Config, load_config, save_config, test_llm_connection
from app.dedup import DuplicateGroup, detect_exact_duplicates
from app.extract import ExtractionResult, extract_text
from app.inventory import InventoryRow, RunSummary, write_inventory, find_latest_run, read_inventory, update_inventory_after_sort
from app.llm_client import LLMClient
from app.loggingx import log_event, log_readable, setup_logging
from app.progress import ProgressTracker
from app.rename import plan_renames
from app.scan import FileMeta, ensure_hash, scan_directory
from app.sortout import delete_duplicates, quarantine_files, sort_files, flatten_directory
from app.theme import THEME, markup, format_number, format_status, format_error, header_line

colorama_init()
console = Console()


@dataclass
class FileContext:
    meta: FileMeta
    text: ExtractionResult
    classification: Dict[str, Optional[str]]
    summary: str
    category: str
    date_doc: str


def show_rename_preview(rename_plans: list, max_preview: int = 50) -> bool:
    """
    ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ð¾Ð¿ÐµÑ€ÐµÐ´Ð½Ñ–Ð¹ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñ–Ð² Ñƒ Ð²Ð¸Ð³Ð»ÑÐ´Ñ– Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ–.

    Args:
        rename_plans: Ð¡Ð¿Ð¸ÑÐ¾Ðº RenamePlan Ð· Ð¿Ð»Ð°Ð½Ð°Ð¼Ð¸ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ
        max_preview: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð° ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð´Ð»Ñ Ð²Ñ–Ð´Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ (Ð·Ð° Ð·Ð°Ð¼Ð¾Ð²Ñ‡ÑƒÐ²Ð°Ð½Ð½ÑÐ¼ 50)

    Returns:
        True ÑÐºÑ‰Ð¾ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ Ð¿Ñ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¸Ð², False ÑÐºÑ‰Ð¾ ÑÐºÐ°ÑÑƒÐ²Ð°Ð²
    """
    console.print(header_line("ÐŸÐžÐŸÐ•Ð Ð•Ð”ÐÐ†Ð™ ÐŸÐ•Ð Ð•Ð“Ð›Ð¯Ð” ÐŸÐ•Ð Ð•Ð™ÐœÐ•ÐÐ£Ð’ÐÐÐÐ¯ Ð¤ÐÐ™Ð›Ð†Ð’"))

    # Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ñ‚Ð°Ð±Ð»Ð¸Ñ†ÑŽ Ð· Ð½Ð¾Ð²Ð¾ÑŽ ÐºÐ¾Ð»ÑŒÐ¾Ñ€Ð¾Ð²Ð¾ÑŽ ÑÑ…ÐµÐ¼Ð¾ÑŽ
    table = Table(show_header=True, header_style=THEME.header, show_lines=True, border_style=THEME.border)
    table.add_column("â„–", style=THEME.dim_text, width=5)
    table.add_column("Ð¡Ñ‚Ð°Ñ€Ðµ Ñ–Ð¼'Ñ", style=THEME.file_name, max_width=40)
    table.add_column("â†’", justify="center", width=3, style=THEME.info)
    table.add_column("ÐÐ¾Ð²Ðµ Ñ–Ð¼'Ñ", style=THEME.success, max_width=40)
    table.add_column("Ð”Ð¾Ð²Ð¶Ð¸Ð½Ð°", justify="right", width=8)
    table.add_column("ÐšÐ¾Ð»Ñ–Ð·Ñ–Ñ", justify="center", width=8)

    total_files = len(rename_plans)
    preview_count = min(max_preview, total_files)

    # Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ñ€ÑÐ´ÐºÐ¸ Ð´Ð¾ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ–
    for idx, plan in enumerate(rename_plans[:preview_count], 1):
        old_name = plan.meta.path.name
        new_name = plan.new_name
        # Ð”Ð¾Ð²Ð¶Ð¸Ð½Ð° Ð±ÐµÐ· Ñ€Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ
        name_without_ext = Path(new_name).stem
        length = len(name_without_ext)
        collision_mark = markup(THEME.warning, "âœ“") if plan.collision else ""

        # ÐŸÑ–Ð´ÑÐ²Ñ–Ñ‚ÐºÐ° ÑÐºÑ‰Ð¾ Ð´Ð¾Ð²Ð¶Ð¸Ð½Ð° Ð±Ñ–Ð»ÑŒÑˆÐµ 20
        if length > 20:
            length_str = markup(THEME.error, str(length))
        else:
            length_str = markup(THEME.success, str(length))

        table.add_row(
            str(idx),
            old_name,
            "â†’",
            new_name,
            length_str,
            collision_mark
        )

    console.print(table)

    # Ð¯ÐºÑ‰Ð¾ Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð±Ñ–Ð»ÑŒÑˆÐµ Ð½Ñ–Ð¶ max_preview
    if total_files > preview_count:
        console.print(markup(THEME.dim_text, f"\n... Ñ– Ñ‰Ðµ {total_files - preview_count} Ñ„Ð°Ð¹Ð»Ñ–Ð²"))

    # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð· Ð½Ð¾Ð²Ð¾ÑŽ ÐºÐ¾Ð»ÑŒÐ¾Ñ€Ð¾Ð²Ð¾ÑŽ ÑÑ…ÐµÐ¼Ð¾ÑŽ
    console.print(f"\n{markup(THEME.title, 'ÐŸÑ–Ð´ÑÑƒÐ¼Ð¾Ðº:')}")
    console.print(f"  â€¢ Ð’ÑÑŒÐ¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ: {format_number(total_files)}")

    collisions = sum(1 for p in rename_plans if p.collision)
    if collisions > 0:
        console.print(f"  â€¢ Ð¤Ð°Ð¹Ð»Ñ–Ð² Ð· ÐºÐ¾Ð»Ñ–Ð·Ñ–ÑÐ¼Ð¸ (Ð´Ð¾Ð´Ð°Ð½Ð¾ ÑÑƒÑ„Ñ–ÐºÑ): {format_number(collisions, THEME.warning)}")

    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð´Ð¾Ð²Ð¶Ð¸Ð½
    too_long = sum(1 for p in rename_plans if len(Path(p.new_name).stem) > 20)
    if too_long > 0:
        console.print(format_error(f"Ð£Ð’ÐÐ“Ð: {too_long} Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð¿ÐµÑ€ÐµÐ²Ð¸Ñ‰ÑƒÑŽÑ‚ÑŒ Ð»Ñ–Ð¼Ñ–Ñ‚ 20 ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ–Ð²!"))

    # Ð—Ð°Ð¿Ð¸Ñ‚ Ð¿Ñ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ð½Ñ
    console.print(f"\n{markup(THEME.warning, 'Ð—Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ñ‚Ð¸ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ?')}")
    prompt_text = markup(THEME.secondary_text, "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ 'y' Ð°Ð±Ð¾ 'yes' Ð´Ð»Ñ Ð¿Ñ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ð½Ñ: ")
    response = input(prompt_text).strip().lower()

    return response in ('y', 'yes', 'Ñ‚Ð°Ðº', 'Ñ‚')


def main() -> None:
    try:
        cfg = load_config()
    except Exception as exc:
        console.print(format_error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ—: {exc}"))
        console.print(markup(THEME.dim_text, "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð° Ð·Ð°Ð¼Ð¾Ð²Ñ‡ÑƒÐ²Ð°Ð½Ð½ÑÐ¼."))
        cfg = Config()

    while True:
        try:
            console.print(f"\n{markup(THEME.title, 'File Inventory Tool')}")
            console.print(markup(THEME.primary_text, "[1] Ð¨Ð²Ð¸Ð´ÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· (dry-run)"))
            console.print(markup(THEME.primary_text, "[2] Ð—Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ñ‚Ð¸ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ (commit)"))
            console.print(markup(THEME.primary_text, "[3] ÐŸÐµÑ€ÐµÐ³Ð»ÑÐ½ÑƒÑ‚Ð¸ Ð¿Ñ–Ð´ÑÑƒÐ¼Ð¾Ðº Ð¾ÑÑ‚Ð°Ð½Ð½ÑŒÐ¾Ð³Ð¾ Ð·Ð°Ð¿ÑƒÑÐºÑƒ"))
            console.print(markup(THEME.primary_text, "[4] ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ"))
            console.print(markup(THEME.primary_text, "[5] Ð’Ñ–Ð´Ð½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð½ÐµÐ·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ð¹ Ð·Ð°Ð¿ÑƒÑÐº"))
            console.print(markup(THEME.primary_text, "[6] Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ñ‚Ð° Ð¿Ð¾Ð´Ð°Ð½Ð½Ñ"))
            console.print(markup(THEME.primary_text, "[7] ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸/Ð¿ÐµÑ€ÐµÑ–Ð½ÑÑ‚Ð°Ð»ÑŽÐ²Ð°Ñ‚Ð¸ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ñ–"))
            console.print(markup(THEME.primary_text, "[8] Ð’Ð¸Ñ…Ñ–Ð´"))
            choice = input("ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ Ð¾Ð¿Ñ†Ñ–ÑŽ: ").strip()
            if choice == "1":
                execute_pipeline(cfg, mode="dry-run")
            elif choice == "2":
                confirm = input("Ð’Ð¸ÐºÐ¾Ð½Ð°Ñ‚Ð¸ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ? [Y/n] ").strip().lower()
                if confirm in {"", "y", "yes"}:
                    delete_choice = input("Ð’Ð¸Ð´Ð°Ð»ÑÑ‚Ð¸ Ñ‚Ð¾Ñ‡Ð½Ñ– Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ð¸ Ð·Ð°Ð¼Ñ–ÑÑ‚ÑŒ ÐºÐ°Ñ€Ð°Ð½Ñ‚Ð¸Ð½Ñƒ? [Y/n] ").strip().lower()
                    delete_exact = delete_choice in {"", "y", "yes"}
                    sort_choice = input("Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ð¿Ð¾ Ð¿Ñ–Ð´Ð¿Ð°Ð¿ÐºÐ°Ñ…? [Y/n] ").strip().lower()
                    sort_strategy = None
                    if sort_choice in {"", "y", "yes"}:
                        console.print(markup(THEME.info, "1 = by_category, 2 = by_date, 3 = by_type"))
                        mapping = {"1": "by_category", "2": "by_date", "3": "by_type"}
                        selected = input("ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–ÑŽ: ").strip()
                        sort_strategy = mapping.get(selected)
                    execute_pipeline(cfg, mode="commit", delete_exact=delete_exact, sort_strategy=sort_strategy)
            elif choice == "3":
                show_last_summary()
            elif choice == "4":
                cfg = configure(cfg)
            elif choice == "5":
                console.print(markup(THEME.warning, "Ð’Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ñ‰Ðµ Ð½Ðµ Ñ€ÐµÐ°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ðµ Ñƒ Ñ†Ñ–Ð¹ Ð²ÐµÑ€ÑÑ–Ñ—."))
            elif choice == "6":
                sort_and_organize(cfg)
            elif choice == "7":
                deps.ensure_ready()
            elif choice == "8":
                console.print(markup(THEME.success, "Ð”Ð¾ Ð¿Ð¾Ð±Ð°Ñ‡ÐµÐ½Ð½Ñ!"))
                break
            else:
                console.print(markup(THEME.warning, "ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ð²Ð¸Ð±Ñ–Ñ€. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·."))
        except KeyboardInterrupt:
            console.print(markup(THEME.warning, "\nÐŸÐµÑ€ÐµÑ€Ð¸Ð²Ð°Ð½Ð½Ñ... Ð—Ð±ÐµÑ€Ñ–Ð³Ð°ÑŽ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑ..."))
            break
        except Exception as exc:
            console.print(f"\n{markup(THEME.error, 'â•â•â• ÐÐµÐ¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° â•â•â•')}")
            console.print(format_error(f"{type(exc).__name__}: {exc}"))
            console.print(markup(THEME.warning, "\nÐÐ°Ñ‚Ð¸ÑÐ½Ñ–Ñ‚ÑŒ Enter Ñ‰Ð¾Ð± Ð¿Ð¾Ð²ÐµÑ€Ð½ÑƒÑ‚Ð¸ÑÑ Ð´Ð¾ Ð¼ÐµÐ½ÑŽ..."))
            input()  # Ð§ÐµÐºÐ°Ñ”Ð¼Ð¾ Ð½Ð°Ñ‚Ð¸ÑÐºÐ°Ð½Ð½Ñ Enter
            # ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶ÑƒÑ”Ð¼Ð¾ Ñ†Ð¸ÐºÐ» - Ð¿Ð¾Ð²ÐµÑ€Ñ‚Ð°Ñ”Ð¼Ð¾ÑÑŒ Ð´Ð¾ Ð¼ÐµÐ½ÑŽ


def configure(cfg: Config) -> Config:
    console.print(header_line("ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ File Inventory Tool"))

    # ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð¿Ð°Ð¿ÐºÐ¸
    console.print(f"{markup(THEME.header, '1. ÐŸÐ°Ð¿ÐºÐ° Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ:')} {cfg.root}")
    new_root = input("   Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ Ð½Ð¾Ð²Ð¸Ð¹ ÑˆÐ»ÑÑ… (Enter Ñ‰Ð¾Ð± Ð»Ð¸ÑˆÐ¸Ñ‚Ð¸): ").strip()
    if new_root:
        cfg.root = Path(new_root)

    # ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ OCR
    console.print(f"\n{markup(THEME.header, '2. ÐœÐ¾Ð²Ð° OCR:')} {cfg.ocr_lang}")
    ocr = input("   Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ Ð¼Ð¾Ð²Ñƒ (ukr+eng/eng/off, Enter Ñ‰Ð¾Ð± Ð»Ð¸ÑˆÐ¸Ñ‚Ð¸): ").strip()
    if ocr:
        cfg.ocr_lang = ocr

    # ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ LLM
    console.print(f"\n{markup(THEME.header, '3. LLM Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ:')}")
    console.print(f"   {markup(THEME.dim_text, 'ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€:')} {cfg.llm_provider}")
    console.print(f"   {markup(THEME.dim_text, 'LLM ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾:')} {cfg.llm_enabled}")

    llm_choice = input("\n   ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ñ‚Ð¸ LLM? [y/N]: ").strip().lower()
    if llm_choice in {"y", "yes"}:
        console.print(f"\n   {markup(THEME.title, 'ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ LLM Ð¿Ñ€Ð¾Ð²Ð°Ð¹Ð´ÐµÑ€Ð°:')}")
        console.print(markup(THEME.primary_text, "   1 = Claude (Anthropic)"))
        console.print(markup(THEME.primary_text, "   2 = ChatGPT (OpenAI)"))
        console.print(markup(THEME.primary_text, "   3 = Ð’Ð¸Ð¼ÐºÐ½ÑƒÑ‚Ð¸ LLM"))

        provider_choice = input("   Ð’Ð°Ñˆ Ð²Ð¸Ð±Ñ–Ñ€ [1-3]: ").strip()

        if provider_choice == "1":
            cfg.llm_provider = "claude"
            cfg.llm_enabled = True

            # API ÐºÐ»ÑŽÑ‡ Claude
            current_key = cfg.llm_api_key_claude
            if current_key:
                console.print(f"   ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÐºÐ»ÑŽÑ‡: {current_key[:10]}...{current_key[-4:]}")
                change = input("   Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ API ÐºÐ»ÑŽÑ‡? [y/N]: ").strip().lower()
                if change in {"y", "yes"}:
                    new_key = input("   Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ API ÐºÐ»ÑŽÑ‡ Claude: ").strip()
                    if new_key:
                        cfg.llm_api_key_claude = new_key
            else:
                new_key = input("   Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ API ÐºÐ»ÑŽÑ‡ Claude: ").strip()
                if new_key:
                    cfg.llm_api_key_claude = new_key

            # ÐœÐ¾Ð´ÐµÐ»ÑŒ
            console.print("   Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð¾Ð²Ð°Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ–:")
            console.print("   - claude-3-5-haiku-20241022 (ÑˆÐ²Ð¸Ð´ÐºÐ°, Ð´ÐµÑˆÐµÐ²Ð°)")
            console.print("   - claude-3-5-sonnet-20241022 (Ð½Ð°Ð¹ÐºÑ€Ð°Ñ‰Ð° Ð´Ð»Ñ Ð±Ñ–Ð»ÑŒÑˆÐ¾ÑÑ‚Ñ–)")
            console.print("   - claude-3-opus-20240229 (Ð½Ð°Ð¹Ð¿Ð¾Ñ‚ÑƒÐ¶Ð½Ñ–ÑˆÐ°)")
            model = input(f"   ÐœÐ¾Ð´ÐµÐ»ÑŒ (Enter Ð´Ð»Ñ {cfg.llm_model or 'claude-3-5-haiku-20241022'}): ").strip()
            if model:
                cfg.llm_model = model
            elif not cfg.llm_model:
                cfg.llm_model = "claude-3-5-haiku-20241022"

            # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ
            if cfg.llm_api_key_claude:
                console.print(markup(THEME.warning, "\n   ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ..."))
                success, message = test_llm_connection("claude", cfg.llm_api_key_claude, cfg.llm_model)
                console.print(f"   {message}")

        elif provider_choice == "2":
            cfg.llm_provider = "chatgpt"
            cfg.llm_enabled = True

            # API ÐºÐ»ÑŽÑ‡ OpenAI
            current_key = cfg.llm_api_key_openai
            if current_key:
                console.print(f"   ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÐºÐ»ÑŽÑ‡: {current_key[:10]}...{current_key[-4:]}")
                change = input("   Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ API ÐºÐ»ÑŽÑ‡? [y/N]: ").strip().lower()
                if change in {"y", "yes"}:
                    new_key = input("   Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ API ÐºÐ»ÑŽÑ‡ OpenAI: ").strip()
                    if new_key:
                        cfg.llm_api_key_openai = new_key
            else:
                new_key = input("   Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ API ÐºÐ»ÑŽÑ‡ OpenAI: ").strip()
                if new_key:
                    cfg.llm_api_key_openai = new_key

            # ÐœÐ¾Ð´ÐµÐ»ÑŒ
            console.print("   Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð¾Ð²Ð°Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ–:")
            console.print("   - gpt-4o-mini (ÑˆÐ²Ð¸Ð´ÐºÐ°, Ð´ÐµÑˆÐµÐ²Ð°)")
            console.print("   - gpt-4o (Ð½Ð°Ð¹ÐºÑ€Ð°Ñ‰Ð° multimodal)")
            console.print("   - gpt-4-turbo (Ð¿Ð¾Ð¿ÐµÑ€ÐµÐ´Ð½Ñ Ñ‚Ð¾Ð¿Ð¾Ð²Ð°)")
            model = input(f"   ÐœÐ¾Ð´ÐµÐ»ÑŒ (Enter Ð´Ð»Ñ {cfg.llm_model or 'gpt-4o-mini'}): ").strip()
            if model:
                cfg.llm_model = model
            elif not cfg.llm_model:
                cfg.llm_model = "gpt-4o-mini"

            # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ
            if cfg.llm_api_key_openai:
                console.print(markup(THEME.warning, "\n   ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ..."))
                success, message = test_llm_connection("chatgpt", cfg.llm_api_key_openai, cfg.llm_model)
                console.print(f"   {message}")

        elif provider_choice == "3":
            cfg.llm_provider = "none"
            cfg.llm_enabled = False
            console.print(markup(THEME.warning, "   LLM Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾"))

    save_config(cfg)
    console.print(format_status("\nÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾.", is_error=False))
    return cfg


def show_last_summary() -> None:
    runs_dir = Path("runs")
    if not runs_dir.exists():
        console.print(markup(THEME.warning, "ÐÐµÐ¼Ð°Ñ” Ð·Ð°Ð¿ÑƒÑÐºÑ–Ð²."))
        return
    run_dirs = sorted([p for p in runs_dir.iterdir() if p.is_dir()])
    if not run_dirs:
        console.print(markup(THEME.warning, "ÐÐµÐ¼Ð°Ñ” Ð·Ð°Ð¿ÑƒÑÐºÑ–Ð²."))
        return
    latest = run_dirs[-1]
    summary_path = latest / "inventory.xlsx"
    console.print(f"{markup(THEME.header, 'ÐžÑÑ‚Ð°Ð½Ð½Ñ–Ð¹ Ð·Ð°Ð¿ÑƒÑÐº:')} {latest.name}")
    console.print(f"{markup(THEME.header, 'Ð¤Ð°Ð¹Ð» Ñ–Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—:')} {summary_path}")


def sort_and_organize(cfg: Config) -> None:
    """ÐžÐºÑ€ÐµÐ¼Ðµ Ð¼ÐµÐ½ÑŽ Ð´Ð»Ñ ÑÐ¾Ñ€Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ñ‚Ð° Ð¾Ñ€Ð³Ð°Ð½Ñ–Ð·Ð°Ñ†Ñ–Ñ— Ñ„Ð°Ð¹Ð»Ñ–Ð²."""
    console.print(header_line("Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ñ‚Ð° Ð¾Ñ€Ð³Ð°Ð½Ñ–Ð·Ð°Ñ†Ñ–Ñ Ñ„Ð°Ð¹Ð»Ñ–Ð²"))

    # Ð—Ð½Ð°Ð¹Ñ‚Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð½Ñ–Ð¹ Ð·Ð°Ð¿ÑƒÑÐº
    latest_run = find_latest_run()
    if not latest_run:
        console.print(format_error("ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°: ÐÐµÐ¼Ð°Ñ” Ð¶Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð¿ÑƒÑÐºÑƒ. Ð¡Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð¹Ñ‚Ðµ Ð°Ð½Ð°Ð»Ñ–Ð· (Ð¿ÑƒÐ½ÐºÑ‚ 1)."))
        return

    console.print(format_status(f"Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ñ‚ÑŒÑÑ Ð·Ð°Ð¿ÑƒÑÐº: {latest_run.name}", is_error=False))

    # ÐŸÑ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚Ð¸ Ñ–Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð·Ð°Ñ†Ñ–ÑŽ
    try:
        df = read_inventory(latest_run)
        console.print(format_status(f"Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð¾ {len(df)} Ð·Ð°Ð¿Ð¸ÑÑ–Ð²", is_error=False))
    except Exception as e:
        console.print(format_error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ñ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ Ñ–Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—: {e}"))
        return

    # ÐœÐµÐ½ÑŽ Ð¾Ð¿Ñ†Ñ–Ð¹
    console.print(f"\n{markup(THEME.title, 'ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ Ð´Ñ–ÑŽ:')}")
    console.print(markup(THEME.primary_text, "[1] Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ð·Ð° ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–ÑÐ¼Ð¸"))
    console.print(markup(THEME.primary_text, "[2] Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ð·Ð° Ð´Ð°Ñ‚Ð°Ð¼Ð¸"))
    console.print(markup(THEME.primary_text, "[3] Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ð·Ð° Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸"))
    console.print(markup(THEME.primary_text, "[4] ÐžÐ±'Ñ”Ð´Ð½Ð°Ñ‚Ð¸ Ð²ÑÑ– Ñ„Ð°Ð¹Ð»Ð¸ Ð· Ð¿Ñ–Ð´Ð¿Ð°Ð¿Ð¾Ðº Ð² Ð¾Ð´Ð½Ñƒ Ð¿Ð°Ð¿ÐºÑƒ"))
    console.print(markup(THEME.primary_text, "[5] ÐŸÐ¾Ð²ÐµÑ€Ð½ÑƒÑ‚Ð¸ÑÑ Ð´Ð¾ Ð³Ð¾Ð»Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ð¼ÐµÐ½ÑŽ"))

    choice = input("\nÐ’Ð°Ñˆ Ð²Ð¸Ð±Ñ–Ñ€: ").strip()

    root = cfg.root_path
    file_updates: Dict[str, str] = {}

    try:
        if choice == "1":
            # Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð° ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–ÑÐ¼Ð¸
            console.print(markup(THEME.processing, "\nÐ¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð° ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–ÑÐ¼Ð¸..."))
            files_to_sort = [Path(row["path_final"]) for _, row in df.iterrows() if Path(row["path_final"]).exists()]
            mapping = sort_files(root, files_to_sort, "by_category", cfg.sorted_root)
            file_updates = {str(k): str(v) for k, v in mapping.items()}
            console.print(format_status(f"Ð’Ñ–Ð´ÑÐ¾Ñ€Ñ‚Ð¾Ð²Ð°Ð½Ð¾ {len(mapping)} Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð·Ð° ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–ÑÐ¼Ð¸", is_error=False))

        elif choice == "2":
            # Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð° Ð´Ð°Ñ‚Ð°Ð¼Ð¸
            console.print(markup(THEME.processing, "\nÐ¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð° Ð´Ð°Ñ‚Ð°Ð¼Ð¸..."))
            files_to_sort = [Path(row["path_final"]) for _, row in df.iterrows() if Path(row["path_final"]).exists()]
            mapping = sort_files(root, files_to_sort, "by_date", cfg.sorted_root)
            file_updates = {str(k): str(v) for k, v in mapping.items()}
            console.print(format_status(f"Ð’Ñ–Ð´ÑÐ¾Ñ€Ñ‚Ð¾Ð²Ð°Ð½Ð¾ {len(mapping)} Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð·Ð° Ð´Ð°Ñ‚Ð°Ð¼Ð¸", is_error=False))

        elif choice == "3":
            # Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð° Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸
            console.print(markup(THEME.processing, "\nÐ¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð° Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸ Ñ„Ð°Ð¹Ð»Ñ–Ð²..."))
            files_to_sort = [Path(row["path_final"]) for _, row in df.iterrows() if Path(row["path_final"]).exists()]
            mapping = sort_files(root, files_to_sort, "by_type", cfg.sorted_root)
            file_updates = {str(k): str(v) for k, v in mapping.items()}
            console.print(format_status(f"Ð’Ñ–Ð´ÑÐ¾Ñ€Ñ‚Ð¾Ð²Ð°Ð½Ð¾ {len(mapping)} Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð·Ð° Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸", is_error=False))

        elif choice == "4":
            # ÐžÐ±'Ñ”Ð´Ð½Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñ–Ð²
            console.print(markup(THEME.processing, "\nÐžÐ±'Ñ”Ð´Ð½Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð· Ð¿Ñ–Ð´Ð¿Ð°Ð¿Ð¾Ðº..."))
            target_name = input("ÐÐ°Ð·Ð²Ð° Ñ†Ñ–Ð»ÑŒÐ¾Ð²Ð¾Ñ— Ð¿Ð°Ð¿ÐºÐ¸ (Enter Ð´Ð»Ñ '_flattened'): ").strip() or "_flattened"
            target_dir = root / target_name

            console.print(markup(THEME.warning, f"Ð’ÑÑ– Ñ„Ð°Ð¹Ð»Ð¸ Ð· {root} Ð±ÑƒÐ´ÑƒÑ‚ÑŒ Ð¿ÐµÑ€ÐµÐ¼Ñ–Ñ‰ÐµÐ½Ñ– Ð² {target_dir}"))
            confirm = input("ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸? [y/N]: ").strip().lower()

            if confirm in {"y", "yes"}:
                mapping = flatten_directory(root, target_dir, recursive=True)
                file_updates = {str(k): str(v) for k, v in mapping.items()}
                console.print(format_status(f"ÐžÐ±'Ñ”Ð´Ð½Ð°Ð½Ð¾ {len(mapping)} Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð² {target_dir}", is_error=False))
            else:
                console.print(markup(THEME.warning, "Ð¡ÐºÐ°ÑÐ¾Ð²Ð°Ð½Ð¾"))
                return

        elif choice == "5":
            return

        else:
            console.print(markup(THEME.warning, "ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ð²Ð¸Ð±Ñ–Ñ€"))
            return

        # ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ Ñ–Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð·Ð°Ñ†Ñ–ÑŽ
        if file_updates:
            console.print(markup(THEME.processing, "\nÐžÐ½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ñ–Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—..."))
            strategy = {"1": "by_category", "2": "by_date", "3": "by_type", "4": "flattened"}.get(choice, "manual")
            update_inventory_after_sort(latest_run, file_updates, strategy)
            console.print(format_status(f"Ð†Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð°: {latest_run / 'inventory.xlsx'}", is_error=False))

    except Exception as e:
        console.print(format_error(f"\nÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ: {e}"))
        import traceback
        console.print(markup(THEME.dim_text, traceback.format_exc()))


def execute_pipeline(cfg: Config, mode: str, delete_exact: bool = False, sort_strategy: Optional[str] = None) -> None:
    start_time = datetime.now(timezone.utc)
    run_id = start_time.strftime("%Y%m%dT%H%M%S")
    run_dir = Path("runs") / run_id

    try:
        setup_logging(run_dir)
        save_config(cfg, run_dir)
    except Exception as exc:
        console.print(format_error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ñ–Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ—: {exc}"))
        return

    tracker = ProgressTracker(
        {
            "scan": 1.0,
            "dedup": 1.0,
            "extract": 2.0,
            "classify": 1.0,
            "rename": 1.0,
            "inventory": 1.0,
        },
        scan_dir=str(cfg.root_path),  # ÐŸÐµÑ€ÐµÐ´Ð°Ñ‚Ð¸ Ð¿Ð°Ð¿ÐºÑƒ ÑÐºÐ°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ
    )

    # Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð²Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑ-Ð±Ð°Ñ€
    mode_text = "ÑˆÐ²Ð¸Ð´ÐºÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ" if mode == "dry-run" else "Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð¼Ñ–Ð½"
    console.print(f"\n{markup(THEME.success, f'Ð—Ð°Ð¿ÑƒÑÐº {mode_text}...')}")
    tracker.start_visual()

    try:
        root = cfg.root_path

        # Validate root path exists
        if not root.exists():
            tracker.stop_visual()
            console.print(format_error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°: Ð¨Ð»ÑÑ… {root} Ð½Ðµ Ñ–ÑÐ½ÑƒÑ”"))
            return

        if not root.is_dir():
            tracker.stop_visual()
            console.print(format_error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°: {root} Ð½Ðµ Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ"))
            return

        # Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ LLM ÐºÐ»Ñ–Ñ”Ð½Ñ‚ ÑÐºÑ‰Ð¾ ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾
        llm_client = None
        if cfg.llm_enabled and cfg.llm_provider != "none":
            api_key = ""
            if cfg.llm_provider == "claude":
                api_key = cfg.llm_api_key_claude
            elif cfg.llm_provider == "chatgpt":
                api_key = cfg.llm_api_key_openai

            if api_key:
                llm_client = LLMClient(
                    provider=cfg.llm_provider,
                    api_key=api_key,
                    model=cfg.llm_model,
                    enabled=True,
                )
                console.print(
                    format_status(f"LLM ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾: {cfg.llm_provider} ({cfg.llm_model or 'default'})", is_error=False)
                )
            else:
                console.print(
                    markup(THEME.warning, "âš  LLM ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾ Ð°Ð»Ðµ API ÐºÐ»ÑŽÑ‡ Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð¾")
                )

        try:
            metas = scan_directory(root)
        except Exception as exc:
            tracker.stop_visual()
            console.print(format_error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÑÐºÐ°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ: {exc}"))
            return

        if not metas:
            tracker.stop_visual()
            console.print(markup(THEME.warning, "ÐŸÐ¾Ð¿ÐµÑ€ÐµÐ´Ð¶ÐµÐ½Ð½Ñ: ÐÐµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸"))
            return

        # ÐŸÑ–ÑÐ»Ñ ÑÐºÐ°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð²ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÑŽÑ”Ð¼Ð¾ total Ð´Ð»Ñ Ð²ÑÑ–Ñ… ÐµÑ‚Ð°Ð¿Ñ–Ð²
        tracker.set_all_totals(len(metas))
        tracker.set_stage_total("scan", len(metas))
        tracker.increment("scan", len(metas))
        tracker.update_description("scan", f"Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(metas)} Ñ„Ð°Ð¹Ð»Ñ–Ð²")

        # Ð—Ð°Ð¿Ð¾Ð²Ð½Ð¸Ñ‚Ð¸ Ñ‡ÐµÑ€Ð³Ñƒ Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð´Ð»Ñ Ñ…Ð°ÐºÐµÑ€ÑÑŒÐºÐ¾Ð³Ð¾ Ñ–Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÑƒ
        file_paths = [str(meta.path) for meta in metas]
        tracker.populate_queue(file_paths)

        update_progress(run_dir, tracker)

        tracker.update_description("dedup", "ÐÐ½Ð°Ð»Ñ–Ð· Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ñ–Ð²...")
        exact_groups: List[DuplicateGroup] = detect_exact_duplicates(metas) if cfg.dedup.exact else []

        # ÐŸÑ–Ð´Ñ€Ð°Ñ…ÑƒÐ½Ð¾Ðº Ñ„Ð°Ð¹Ð»Ñ–Ð²-Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ñ–Ð²
        duplicate_files_count = sum(len(group.files) - 1 for group in exact_groups)

        # ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ñ–Ð²
        tracker.update_metrics(
            duplicate_groups=len(exact_groups),
            duplicate_files=duplicate_files_count
        )

        tracker.increment("dedup", len(metas))
        tracker.update_description("dedup", f"Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(exact_groups)} Ð³Ñ€ÑƒÐ¿ Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ñ–Ð²")
        update_progress(run_dir, tracker)

        file_contexts: Dict[Path, FileContext] = {}
        tracker.set_stage_total("extract", len(metas))
        error_count = 0
        for idx, meta in enumerate(metas, 1):
            # Ð’Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ Ð· Ñ‡ÐµÑ€Ð³Ð¸
            tracker.remove_from_queue(meta.path.name)

            # Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ Ñ„Ð°Ð¹Ð»
            tracker.set_current_file(
                name=meta.path.name,
                path=str(meta.path),
                stage="extract",
                status="processing",
            )

            tracker.update_description("extract", f"{meta.path.name} ({idx}/{len(metas)})")

            # Ð—Ð°ÑÑ–ÐºÑ‚Ð¸ Ñ‡Ð°Ñ Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸
            start_time = time.time()
            try:
                ensure_hash(meta)

                # Ð•Ñ‚Ð°Ð¿ 1: Ð’Ð¸Ð»ÑƒÑ‡ÐµÐ½Ð½Ñ Ñ‚ÐµÐºÑÑ‚Ñƒ
                result = extract_text(meta, cfg.ocr_lang)

                # ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð¿Ñ–ÑÐ»Ñ extract
                tracker.set_current_file(
                    name=meta.path.name,
                    stage="extract",
                    status="success",
                )

                # Ð•Ñ‚Ð°Ð¿ 2: ÐšÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ Ñ‡ÐµÑ€ÐµÐ· LLM
                tracker.set_current_file(
                    name=meta.path.name,
                    stage="classify",
                    status="processing",
                )

                classification = classify_text(result.text, llm_client=llm_client)
                category = classification.get("category") or "Ñ–Ð½ÑˆÐµ"
                date_doc = classification.get("date_doc") or datetime.fromtimestamp(meta.mtime).date().isoformat()
                # Ð¯ÐºÑ‰Ð¾ LLM Ð¿Ð¾Ð²ÐµÑ€Ð½ÑƒÐ² summary, Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ð¼Ð¾ Ð¹Ð¾Ð³Ð¾
                summary = classification.get("summary") or summarize_text(result.text, llm_client=llm_client)
                file_contexts[meta.path] = FileContext(
                    meta=meta,
                    text=result,
                    classification=classification,
                    summary=summary,
                    category=category,
                    date_doc=date_doc,
                )

                # Ð£ÑÐ¿Ñ–ÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¾
                extract_time = time.time() - start_time

                # ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ (Ð‘Ð•Ð— Ð·Ð¼Ñ–Ð½Ð¸ path!)
                tracker.set_current_file(
                    name=meta.path.name,
                    category=category,
                    stage="classify",
                    status="success",
                )

                # Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð² Ð»Ð¾Ð³
                llm_response = classification.get("summary", "") or summary
                tracker.add_to_log(
                    status="success",
                    text_length=len(result.text),
                    llm_response=llm_response[:100] if llm_response else "",  # ÐŸÐµÑ€ÑˆÑ– 100 ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ–Ð²
                    category=category,
                    processing_time={
                        "extract": extract_time,
                        "classify": extract_time,  # ÐžÐ±Ð¸Ð´Ð²Ð° ÐµÑ‚Ð°Ð¿Ð¸ Ð²Ñ–Ð´Ð±ÑƒÐ²Ð°ÑŽÑ‚ÑŒÑÑ Ñ€Ð°Ð·Ð¾Ð¼
                    },
                )

            except Exception as exc:
                # Use fallback values if extraction fails
                error_count += 1
                error_msg = f"ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¾Ð±Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸: {exc}"
                console.print(markup(THEME.warning, f"âš  {error_msg}"))
                extract_time = time.time() - start_time

                # ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸ (Ð‘Ð•Ð— Ð·Ð¼Ñ–Ð½Ð¸ path!)
                tracker.set_current_file(
                    name=meta.path.name,
                    stage="extract",
                    status="error",
                    error_msg=str(exc),
                )

                file_contexts[meta.path] = FileContext(
                    meta=meta,
                    text=ExtractionResult(text="", source="error", quality=0.0),
                    classification={"category": "Ñ–Ð½ÑˆÐµ", "date_doc": None},
                    summary="",
                    category="Ñ–Ð½ÑˆÐµ",
                    date_doc=datetime.fromtimestamp(meta.mtime).date().isoformat(),
                )

                # Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð² Ð»Ð¾Ð³ ÑÐº Ð¿Ð¾Ð¼Ð¸Ð»ÐºÑƒ (Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾Ð½Ð¾Ð²Ð»ÑÑ‚ÑŒÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾)
                tracker.add_to_log(
                    status="error",
                    processing_time={"extract": extract_time},
                )

            tracker.increment("extract")

        update_progress(run_dir, tracker)

        tracker.set_stage_total("classify", len(metas))
        tracker.increment("classify", len(metas))
        tracker.update_description("classify", "ÐšÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–ÑŽ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾")
        update_progress(run_dir, tracker)

        duplicates_map: Dict[Path, Dict[str, Optional[str]]] = {}
        duplicates_files_map: Dict[str, List[Path]] = {}
        for group in exact_groups:
            canonical = group.canonical()
            duplicates_files_map[group.group_id] = []
            ordered_files = sorted(
                group.files,
                key=lambda m: (m.path != canonical.path, m.path),
            )
            for idx, file_meta in enumerate(ordered_files):
                info: Dict[str, Optional[str]] = {
                    "dup_type": "exact_dup",
                    "dup_group_id": group.group_id,
                    "dup_rank": f"V{idx + 1}",
                    "dup_master_path": str(canonical.path),
                }
                duplicates_map[file_meta.path] = info
                if file_meta.path != canonical.path:
                    duplicates_files_map[group.group_id].append(file_meta.path)

        rename_candidates = [meta for meta in metas if duplicates_map.get(meta.path, {}).get("dup_rank", "V1") == "V1"]
        contexts_for_rename: Dict[Path, Dict[str, str]] = {}
        for meta in rename_candidates:
            ctx = file_contexts[meta.path]
            # ÐŸÐµÑ€ÐµÐ´Ð°Ñ”Ð¼Ð¾ Ð¿Ð¾Ð²Ð½Ñƒ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–ÑŽ Ñ‚Ð° Ð´Ð°Ñ‚Ñƒ Ð´Ð»Ñ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ
            contexts_for_rename[meta.path] = {
                "category": ctx.category,
                "date_doc": ctx.date_doc,
                "yyyy": ctx.date_doc[:4] if len(ctx.date_doc) >= 4 else "2024",
                "mm": ctx.date_doc[5:7] if len(ctx.date_doc) >= 7 else "01",
                "dd": ctx.date_doc[8:10] if len(ctx.date_doc) >= 10 else "01",
                "ext": meta.path.suffix,
            }

        # Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð½Ð¾Ð²Ð¸Ñ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ–Ð² Ð´Ð»Ñ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾Ð³Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ
        rename_plans = plan_renames(
            rename_candidates,
            cfg.rename_template,
            contexts_for_rename,
            use_short_format=cfg.use_short_format,
            use_short_date=cfg.use_short_date
        )

        # ÐŸÐ¾Ð¿ÐµÑ€ÐµÐ´Ð½Ñ–Ð¹ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ (Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð´Ð»Ñ commit Ñ€ÐµÐ¶Ð¸Ð¼Ñƒ)
        if mode == "commit" and rename_plans:
            tracker.stop_visual()
            console.print(f"\n{markup(THEME.success, 'ÐŸÐ»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾!')}")

            # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ð¾Ð¿ÐµÑ€ÐµÐ´Ð½Ñ–Ð¹ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´ Ñ– Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ñ‚Ð¸ Ð¿Ñ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ð½Ñ
            confirmed = show_rename_preview(rename_plans)

            if not confirmed:
                console.print(markup(THEME.warning, "\nâœ— ÐŸÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐºÐ°ÑÐ¾Ð²Ð°Ð½Ð¾ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ÐµÐ¼"))
                console.print(markup(THEME.dim_text, "Ð†Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Ð±ÑƒÐ´Ðµ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð° Ð±ÐµÐ· Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½Ð½Ñ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ\n"))
                # Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ð¸ Ñ€ÐµÐ¶Ð¸Ð¼ Ð½Ð° dry-run Ñ‰Ð¾Ð± Ð½Ðµ Ð·Ð°ÑÑ‚Ð¾ÑÐ¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð¼Ñ–Ð½Ð¸
                mode = "dry-run"

            # Ð’Ñ–Ð´Ð½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð²Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑ
            continue_text = "Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð¼Ñ–Ð½" if mode == "commit" else "Ð±ÐµÐ· Ð·Ð¼Ñ–Ð½"
            console.print(f"\n{markup(THEME.success, f'ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶ÐµÐ½Ð½Ñ {continue_text}...')}")
            tracker.start_visual()

        rows: List[InventoryRow] = []
        row_map: Dict[Path, InventoryRow] = {}
        path_to_row: Dict[Path, InventoryRow] = {}

        tracker.set_stage_total("rename", len(rename_plans))
        renamed_ok = 0
        renamed_failed = 0
        for idx, plan in enumerate(rename_plans, 1):
            # ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ„Ð°Ð¹Ð»Ñƒ Ð´Ð»Ñ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ—
            ctx = file_contexts.get(plan.meta.path)
            category = ctx.category if ctx else "Ñ–Ð½ÑˆÐµ"

            # Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ Ñ„Ð°Ð¹Ð»
            tracker.set_current_file(
                name=plan.meta.path.name,
                path=str(plan.meta.path),
                category=category,
                stage="Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ",
                status="processing",
            )

            tracker.update_description("rename", f"{plan.meta.path.name} â†’ {plan.new_name} ({idx}/{len(rename_plans)})")
            target = plan.meta.path.with_name(plan.new_name)
            status = "skipped" if mode == "dry-run" else "success"
            error = ""
            if mode == "commit":
                try:
                    plan.meta.path.rename(target)
                    renamed_ok += 1
                    # Ð£ÑÐ¿Ñ–ÑˆÐ½Ð¾ Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¾
                    tracker.set_current_file(
                        name=plan.new_name,
                        category=category,
                        stage="Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ",
                        status="success",
                    )
                except Exception as exc:
                    status = "failed"
                    error = str(exc)
                    renamed_failed += 1
                    target = plan.meta.path
                    # ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ
                    tracker.set_current_file(
                        name=plan.meta.path.name,
                        category=category,
                        stage="Ð¿ÐµÑ€ÐµÐ¹Ð¼ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ",
                        status="error",
                        error_msg=str(exc),
                    )
            tracker.increment("rename")

            # ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾ÑÑ‚Ñ–
            tracker.update_metrics(
                success_count=renamed_ok,
                error_count=renamed_failed
            )

            meta_path = plan.meta.path
            ctx = file_contexts[meta_path]
            dup_info = duplicates_map.get(
                meta_path,
                {"dup_type": "unique", "dup_group_id": None, "dup_rank": "V1", "dup_master_path": None},
            )
            row = InventoryRow(
                root=str(root),
                folder_old=str(meta_path.parent),
                path_old=str(meta_path),
                name_old=meta_path.name,
                name_new=target.name,
                folder_new=str(target.parent),
                path_new=str(target),
                sorted=False,
                sort_strategy=sort_strategy or "",
                sorted_subfolder="",
                path_final=str(target),
                ext=meta_path.suffix.lower(),
                mime=mimetypes.guess_type(meta_path.name)[0] or "application/octet-stream",
                size_mb=plan.meta.size / (1024 * 1024),
                ctime=datetime.fromtimestamp(plan.meta.ctime),
                mtime=datetime.fromtimestamp(plan.meta.mtime),
                date_doc=ctx.date_doc,
                category=ctx.category,
                short_title=ctx.summary,
                version="01",
                hash8=(plan.meta.sha256 or "0" * 8)[:8],
                content_hash_sha256=plan.meta.sha256 or "",
                dup_type=dup_info["dup_type"],
                dup_group_id=dup_info["dup_group_id"],
                dup_rank=dup_info["dup_rank"],
                dup_master_path=dup_info["dup_master_path"],
                near_dup_score=None,
                lifecycle_state="present",
                deleted_ts=None,
                text_source=ctx.text.source,
                ocr_lang=cfg.ocr_lang,
                text_len=len(ctx.text.text),
                extract_quality=ctx.text.quality,
                llm_used=cfg.llm_enabled,
                llm_confidence=None,
                llm_keywords="",
                summary_200=ctx.summary,
                rename_status=status,
                error_message=error,
                collision=plan.collision,
                duration_s=0.0,
                mode=mode,
            )
            rows.append(row)
            row_map[meta_path] = row
            path_to_row[Path(row.path_new)] = row
        update_progress(run_dir, tracker)

        for meta in metas:
            if meta.path in row_map:
                continue
            ctx = file_contexts[meta.path]
            dup_info = duplicates_map.get(
                meta.path,
                {"dup_type": "unique", "dup_group_id": None, "dup_rank": "V1", "dup_master_path": None},
            )
            row = InventoryRow(
                root=str(root),
                folder_old=str(meta.path.parent),
                path_old=str(meta.path),
                name_old=meta.path.name,
                name_new=meta.path.name,
                folder_new=str(meta.path.parent),
                path_new=str(meta.path),
                sorted=False,
                sort_strategy=sort_strategy or "",
                sorted_subfolder="",
                path_final=str(meta.path),
                ext=meta.path.suffix.lower(),
                mime=mimetypes.guess_type(meta.path.name)[0] or "application/octet-stream",
                size_mb=meta.size / (1024 * 1024),
                ctime=datetime.fromtimestamp(meta.ctime),
                mtime=datetime.fromtimestamp(meta.mtime),
                date_doc=ctx.date_doc,
                category=ctx.category,
                short_title=ctx.summary,
                version="01",
                hash8=(meta.sha256 or "0" * 8)[:8],
                content_hash_sha256=meta.sha256 or "",
                dup_type=dup_info["dup_type"],
                dup_group_id=dup_info["dup_group_id"],
                dup_rank=dup_info["dup_rank"],
                dup_master_path=dup_info["dup_master_path"],
                near_dup_score=None,
                lifecycle_state="present",
                deleted_ts=None,
                text_source=ctx.text.source,
                ocr_lang=cfg.ocr_lang,
                text_len=len(ctx.text.text),
                extract_quality=ctx.text.quality,
                llm_used=cfg.llm_enabled,
                llm_confidence=None,
                llm_keywords="",
                summary_200=ctx.summary,
                rename_status="skipped",
                error_message="",
                collision=False,
                duration_s=0.0,
                mode=mode,
            )
            rows.append(row)
            row_map[meta.path] = row
            path_to_row[Path(row.path_new)] = row

        deleted_set: set[Path] = set()
        quarantine_updates: Dict[Path, str] = {}
        duplicates_flat = [path for paths in duplicates_files_map.values() for path in paths]
        if mode == "commit" and duplicates_flat:
            if delete_exact:
                delete_duplicates(duplicates_flat)
                deleted_set.update(duplicates_flat)
            else:
                mapping = quarantine_files(root, duplicates_files_map)
                for original, new_path in mapping.items():
                    quarantine_updates[original] = str(new_path)

        sorted_updates: Dict[Path, Path] = {}
        if mode == "commit" and sort_strategy:
            excluded = {Path(str(p)) for p in deleted_set.union(quarantine_updates.keys())}
            sortable_paths = [
                Path(row.path_new)
                for row in rows
                if row.lifecycle_state == "present" and Path(row.path_new) not in excluded
            ]
            sorted_mapping = sort_files(root, sortable_paths, sort_strategy, cfg.sorted_root)
            sorted_updates.update(sorted_mapping)

        if deleted_set or quarantine_updates:
            now = datetime.now(timezone.utc)
            for original in deleted_set:
                row = row_map.get(original)
                if not row:
                    row = path_to_row.get(original)
                if not row:
                    continue
                row.lifecycle_state = "deleted"
                row.deleted_ts = now
                row.path_final = ""
            for original, state in quarantine_updates.items():
                row = row_map.get(original)
                if not row:
                    row = path_to_row.get(original)
                if not row:
                    continue
                row.lifecycle_state = "quarantined"
                row.path_final = state
                path_to_row[Path(state)] = row

        if sorted_updates:
            for original, new_path in sorted_updates.items():
                row = path_to_row.get(original)
                if not row:
                    continue
                row.sorted = True
                row.sort_strategy = sort_strategy or ""
                row.sorted_subfolder = str(Path(new_path).parent)
                row.path_final = str(new_path)
                path_to_row[Path(new_path)] = row

        tracker.increment("inventory")
        duration = (datetime.now(timezone.utc) - start_time).total_seconds()
        summary = RunSummary(
            run_id=run_id,
            files_total=len(metas),
            files_processed=len(rows),
            renamed_ok=renamed_ok,
            renamed_failed=renamed_failed,
            duplicate_groups=len(exact_groups),
            duplicate_files=len(duplicates_flat),
            near_duplicate_files=0,
            quarantined_count=len(quarantine_updates),
            deleted_count=len(deleted_set),
            ocr_share=sum(1 for row in rows if row.text_source == "ocr") / len(rows) if rows else 0.0,
            llm_share=sum(1 for row in rows if row.llm_used) / len(rows) if rows else 0.0,
            collisions=sum(1 for row in rows if row.collision),
            duration_total_s=duration,
            cost_total_usd=0.0,
            total_size_mb=sum(row.size_mb for row in rows),
            sorted_enabled=bool(sort_strategy),
            sorting_strategy=sort_strategy or "",
            moved_count=len(quarantine_updates) + len(sorted_updates),
            sorted_root=cfg.sorted_root,
            excel_updated=True,
        )

        try:
            write_inventory(rows, summary, run_dir)
            update_progress(run_dir, tracker)
            tracker.stop_visual()
            console.print(format_status(f"\nÐ—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾. Ð”Ð°Ð½Ñ– Ñƒ {run_dir}", is_error=False))
            console.print(f"{markup(THEME.header, 'ÐžÐ±Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ñ–Ð²:')} {format_number(summary.files_processed)}")
            console.print(f"{markup(THEME.header, 'ÐŸÐµÑ€ÐµÐ¹Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¾:')} {format_number(summary.renamed_ok)}")
            if summary.duplicate_files > 0:
                console.print(f"{markup(THEME.duplicate, 'Ð”ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ñ–Ð²:')} {format_number(summary.duplicate_files, THEME.duplicate_count)}")

            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° LLM
            if llm_client:
                stats = llm_client.get_stats()
                if stats["requests"] > 0:
                    # ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ LLM
                    tracker.update_metrics(
                        llm_requests=stats["requests"],
                        llm_responses=stats["requests"]  # ÐšÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÐµÐ¹ = ÐºÑ–Ð»ÑŒÐºÐ¾ÑÑ‚Ñ– Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð²
                    )
                    console.print(
                        f"{markup(THEME.llm_request, 'ðŸ¤– LLM Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð²:')} {format_number(stats['requests'])}, "
                        f"{markup(THEME.llm_request, 'Ñ‚Ð¾ÐºÐµÐ½Ñ–Ð²:')} {format_number(stats['tokens'])}"
                    )
        except Exception as exc:
            tracker.stop_visual()
            console.print(format_error(f"\nÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÑƒ Ñ–Ð½Ð²ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—: {exc}"))
            return

    except Exception as exc:
        # Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ° Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº - Ð·ÑƒÐ¿Ð¸Ð½ÑÑ”Ð¼Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑ-Ð±Ð°Ñ€
        tracker.stop_visual()
        console.print(f"\n{markup(THEME.error, 'â•â•â• ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ â•â•â•')}")
        console.print(format_error(f"{type(exc).__name__}: {exc}"))
        import traceback
        console.print(f"\n{markup(THEME.dim_text, 'Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð° Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ:')}")
        console.print(markup(THEME.dim_text, traceback.format_exc()))
        raise  # ÐŸÐµÑ€ÐµÐ´Ð°Ñ”Ð¼Ð¾ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÑƒ Ð²Ð¸Ñ‰Ðµ


def update_progress(run_dir: Path, tracker: ProgressTracker) -> None:
    snapshot = {
        "percentage": tracker.percentage(),
        "eta_seconds": tracker.eta_seconds(),
        "stages": tracker.snapshot(),
    }
    progress_path = run_dir / "progress.json"
    progress_path.parent.mkdir(parents=True, exist_ok=True)
    progress_path.write_text(json.dumps(snapshot, ensure_ascii=False, indent=2), encoding="utf-8")


if __name__ == "__main__":
    main()

